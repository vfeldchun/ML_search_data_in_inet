# ML_search_data_in_inet
## Методы сбора и обработки данных из сети Интернет
### Домашнее задание к Уроку 5
#### Парсинг данных. Scrapy. Начало

Стек:
ML: scrapy, pymongo

Задача:

####Вариант I

Написать программу, которая собирает входящие письма из своего или тестового почтового ящика и сложить данные о письмах в базу данных (от кого, дата отправки, тема письма, текст письма полный)

Для этого нужно создать свой тестовый почтовый ящик и переслать на него минимум любых рекламных 50 сообщений.

###Вариант II

Написать программу, которая собирает товары «В тренде» с сайта техники mvideo и складывает данные в БД. Сайт можно выбрать и свой. Главный критерий выбора: динамически загружаемые товары

Если mvideo не доступен (что иногда бывает), можете использовать любой сайт с лентой специальных предложений, к примеру: https://www.eldorado.ru/, https://5ka.ru/, https://www.carrefoursa.com/ и т.п.

Описание решения
Для реализации был выбрано задание из Варианта II.
Для реализации парсинга был выбран сайт pleer.ru.
На сайте парсим динамическии изменяемый блок "Распродажа".


Из данного блока забираем все ссылки на страницы всех представленных товаров и затем парсим с каждой страницы тавара следующие атрибуты:

    Наименование товара, cсылка на страницу, ссылка на фото, валюту стоимости и три варрианта цены с поясняющими условиями.
    
Затем записываем все полученные данне по тавару в документальную БД - MongoDB развернутую локально.

Скриншот MongoDB Compass с записыными данными по товарам находяться в каталоге Lesson5/pics/

Scrapy проект находиться в каталоге Lesson5/parser_shop
Структура проекта стандартная. Используються следующие элементы:
    
    1. Паук spiders/pleer_ru.py 
    2. items.py
    3. pipeline.py

Все настройки scrapy в файле setting.py
    

Для запуска:
<your path>/parser_shop/parser_shop/scrapy crawl pleer_ru
